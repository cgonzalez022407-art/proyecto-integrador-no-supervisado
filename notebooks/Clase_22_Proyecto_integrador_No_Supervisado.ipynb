{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Science - ICARO\n",
        "_________________________________\n",
        "Clase: 22\n",
        "\n",
        "Tema: Proyecto integrador - No Supervisado\n",
        "_________________________________\n"
      ],
      "metadata": {
        "id": "PJXTdiyJczTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo:\n",
        "- Aplicar algoritmos de Clustering (KMeans, DBSCAN) para descubrir agrupaciones naturales en el dataset \"Wine Quality\".\n",
        "- Utilizar técnicas de Reducción de Dimensionalidad (PCA, t-SNE, UMAP) para visualizar la estructura de los datos y los clusters.\n",
        "- Interpretar los resultados de los métodos no supervisados y las visualizaciones, extrayendo conclusiones sobre la organización intrínseca de los datos de vino.\n",
        "\n",
        "---\n",
        "\n",
        "## Índice\n",
        "\n",
        "1. [Imports y Configuración Inicial](#imports)\n",
        "2. [Carga y Preparación de Datos](#carga)\n",
        "3. [Análisis Exploratorio de Datos (EDA)](#eda)\n",
        "4. [**Tarea 1: Clustering (Descubrir Grupos de Vino)**](#clustering)\n",
        "    - 4.1. [Preparación de Datos para Clustering](#prep_clustering)\n",
        "    - 4.2. [Modelo de Clustering 1: KMeans](#kmeans)\n",
        "    - 4.3. [Modelo de Clustering 2: DBSCAN](#dbscan)\n",
        "    - 4.4. [**(A COMPLETAR) Tareas Finales de Clustering y Conclusión**](#conclusion_clustering)\n",
        "5. [**Tarea 2: Reducción de Dimensionalidad y Visualización**](#reduccion_dim)\n",
        "    - 5.1. [Preparación de Datos para Reducción de Dimensionalidad](#prep_reduccion)\n",
        "    - 5.2. [Técnica de Reducción 1: PCA para Visualización](#pca)\n",
        "    - 5.3. [Técnica de Reducción 2: t-SNE para Visualización](#tsne)\n",
        "    - 5.4. [Técnica de Reducción 3: UMAP para Visualización](#umap)\n",
        "    - 5.5. [**(A COMPLETAR) Tareas Finales de Reducción y Conclusión**](#conclusion_reduccion)\n",
        "6. [**(A COMPLETAR) Conclusiones Finales del Proyecto**](#final)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "c7mPwfU1drJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"imports\"></a>\n",
        "# 1. Imports y Configuración Inicial\n",
        "En esta primera celda, importaremos todas las librerías que necesitaremos para nuestro análisis de modelos no supervisados."
      ],
      "metadata": {
        "id": "duTItgOydHY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install umap-learn"
      ],
      "metadata": {
        "id": "cYqIBra9tlf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY1q544Rcyx-"
      },
      "outputs": [],
      "source": [
        "# Manipulación de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualización\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Modelos y Preprocesamiento\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import umap.umap_ as umap # Asegúrate de tener instalado 'umap-learn': pip install umap-learn\n",
        "\n",
        "# Métricas de evaluación para clustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Configuración de visualización\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['legend.fontsize'] = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"carga\"></a>\n",
        "## 2. Carga y Preparación de Datos\n",
        "Vamos a cargar los dos datasets (vino tinto y vino blanco), añadiremos una columna para identificar el tipo de vino y luego los uniremos en un único DataFrame."
      ],
      "metadata": {
        "id": "CK3OqNGV1bHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL9SUJIcHUf3"
      },
      "outputs": [],
      "source": [
        "# URLs de los datasets\n",
        "url_red = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "url_white = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
        "\n",
        "# Carga de los dataframes\n",
        "df_red = pd.read_csv(url_red, sep=';')\n",
        "df_white = pd.read_csv(url_white, sep=';')\n",
        "\n",
        "# Creación de la columna 'wine_type' (0 para tinto, 1 para blanco)\n",
        "df_red['wine_type'] = 0\n",
        "df_white['wine_type'] = 1\n",
        "\n",
        "# Unión de los dataframes\n",
        "df = pd.concat([df_red, df_white], axis=0)\n",
        "\n",
        "# Reseteamos el índice\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Forma del dataset combinado:\", df.shape)\n",
        "print(\"\\nPrimeras 5 filas:\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"eda\"></a>\n",
        "## 3. Análisis Exploratorio de Datos (EDA)\n",
        "Antes de modelar, es crucial entender y preparar nuestros datos. Reutilizaremos el EDA básico del Módulo 2."
      ],
      "metadata": {
        "id": "R4s20o6mIe8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8i-vKjIIe8s"
      },
      "outputs": [],
      "source": [
        "print(\"Información general del DataFrame:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nEstadísticas descriptivas de las variables numéricas:\")\n",
        "display(df.describe())\n",
        "\n",
        "print(\"\\nValores nulos por columna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='quality', data=df, palette='viridis')\n",
        "plt.title('Distribución de la Calidad del Vino')\n",
        "plt.xlabel('Calidad del Vino (0-10)')\n",
        "plt.ylabel('Cantidad de Vinos')\n",
        "plt.show()\n",
        "\n",
        "# Matriz de correlación de las variables fisicoquímicas\n",
        "plt.figure(figsize=(12, 10))\n",
        "# Excluimos las columnas 'wine_type' y 'quality' para la matriz de correlación de features\n",
        "correlation_matrix = df.drop(['wine_type', 'quality'], axis=1).corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Matriz de Correlación de las Features Fisicoquímicas')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (A COMPLETAR) Análisis del EDA\n",
        "Basado en los resultados anteriores, comenta tus observaciones sobre:\n",
        "- La distribución de las variables.\n",
        "- La presencia de valores nulos (si los hay).\n",
        "- Las correlaciones entre las características. ¿Hay alguna que te llame la atención?"
      ],
      "metadata": {
        "id": "E1sVwWk-b4a1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"clustering\"></a>\n",
        "# 4. Tarea 1: Clustering (Descubrir Grupos de Vino)\n",
        "En esta sección, aplicaremos algoritmos de clustering para identificar agrupaciones naturales dentro de nuestro dataset de vinos, sin utilizar las etiquetas de `wine_type` o `quality`."
      ],
      "metadata": {
        "id": "M7p2bNqg_xSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"prep_clustering\"></a>\n",
        "### 4.1. Preparación de Datos para Clustering\n",
        "Para el clustering, solo usaremos las características fisicoquímicas de los vinos, y es **crucial** que estén escaladas. Las etiquetas originales (`wine_type`, `quality`) las guardaremos para una posterior comparación y análisis."
      ],
      "metadata": {
        "id": "eJ1-wU9N_y6y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8V0rX86_xSk"
      },
      "outputs": [],
      "source": [
        "# Definir X (features) y las etiquetas originales (y_type, y_quality) para comparación\n",
        "X = df.drop(['wine_type', 'quality'], axis=1)\n",
        "y_type = df['wine_type']\n",
        "y_quality = df['quality']\n",
        "\n",
        "print(f\"Dimensiones de X para clustering: {X.shape}\")\n",
        "\n",
        "# Escalar las características (fundamental para algoritmos basados en distancia)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"\\nPrimeras 5 filas de X escalado:\")\n",
        "print(pd.DataFrame(X_scaled, columns=X.columns).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"kmeans\"></a>\n",
        "### 4.2. Modelo de Clustering 1: KMeans\n",
        "KMeans es un algoritmo de clustering que busca dividir $N$ observaciones en $K$ clusters, donde cada observación pertenece al cluster con la media (centroide) más cercana. Es nuestro punto de partida para identificar grupos."
      ],
      "metadata": {
        "id": "tD-2zXgH_xSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TAREAS EN EL NOTEBOOK:\n",
        "1.  **Paso 1: Determinar K óptimo (Método del Codo).**\n",
        "    * Iterar `K` desde 1 hasta 15 (o un rango similar).\n",
        "    * Para cada `K`, entrenar un modelo `KMeans` con `X_scaled` y guardar la inercia.\n",
        "    * Graficar la inercia vs. `K`.\n",
        "    * Identificar el `K_elegido` donde la curva forma un \"codo\" y justificar su elección en un comentario markdown."
      ],
      "metadata": {
        "id": "g-f5lU6m_xSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP9fA5oN_xSm"
      },
      "outputs": [],
      "source": [
        "inertia = []\n",
        "k_range = range(1, 15) # Probamos K desde 1 hasta 14\n",
        "\n",
        "for k in k_range:\n",
        "    # n_init='auto' es el valor por defecto para versiones recientes, o 10 para compatibilidad.\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, inertia, marker='o')\n",
        "plt.title('Método del Codo para KMeans')\n",
        "plt.xlabel('Número de Clusters (K)')\n",
        "plt.ylabel('Inercia')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# (A COMPLETAR) Justifica tu elección de K aquí\n",
        "# Por ejemplo: \"Observando el gráfico del método del codo, el punto de inflexión más pronunciado parece estar en K = X. Por lo tanto, elegimos X clusters.\"\n",
        "k_elegido = None # Reemplaza None con el valor de K que elegiste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Paso 2: Ejecutar KMeans.**\n",
        "    * Inicializar y entrenar `KMeans` con `n_clusters=K_elegido` y `random_state=42`.\n",
        "    * Obtener las asignaciones de cluster usando `.fit_predict(X_scaled)`. Guardar en la variable `clusters_kmeans`.\n",
        "    * Mostrar la cuenta de puntos por cluster (usando `pd.Series(clusters_kmeans).value_counts()`)."
      ],
      "metadata": {
        "id": "r8P_o5oN_xSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE7yP5oN_xSo"
      },
      "outputs": [],
      "source": [
        "if k_elegido is not None:\n",
        "    kmeans_final = KMeans(n_clusters=k_elegido, random_state=42, n_init=10)\n",
        "    clusters_kmeans = kmeans_final.fit_predict(X_scaled)\n",
        "\n",
        "    print(f\"Número de puntos por cluster (KMeans con K={k_elegido}):\")\n",
        "    print(pd.Series(clusters_kmeans).value_counts().sort_index())\n",
        "else:\n",
        "    print(\"Por favor, define 'k_elegido' en la celda anterior.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Paso 3: Evaluación de KMeans con Silhouette Score.**\n",
        "    * Calcular y mostrar el `silhouette_score(X_scaled, clusters_kmeans)`.\n",
        "    * Opcional: Calcular Calinski-Harabasz Score y Davies-Bouldin Score."
      ],
      "metadata": {
        "id": "u4f2A5oN_xSp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8k-B5oN_xSp"
      },
      "outputs": [],
      "source": [
        "if 'clusters_kmeans' in locals():\n",
        "    silhouette_avg_kmeans = silhouette_score(X_scaled, clusters_kmeans)\n",
        "    print(f\"Silhouette Score para KMeans (K={k_elegido}): {silhouette_avg_kmeans:.3f}\")\n",
        "\n",
        "    calinski_kmeans = calinski_harabasz_score(X_scaled, clusters_kmeans)\n",
        "    davies_kmeans = davies_bouldin_score(X_scaled, clusters_kmeans)\n",
        "    print(f\"Calinski-Harabasz Score para KMeans: {calinski_kmeans:.3f}\")\n",
        "    print(f\"Davies-Bouldin Score para KMeans: {davies_kmeans:.3f}\")\n",
        "else:\n",
        "    print(\"Por favor, ejecuta las celdas anteriores para generar los clusters de KMeans.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Completar curvas de cada métrica**"
      ],
      "metadata": {
        "id": "kYJN3dSVzCOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"dbscan\"></a>\n",
        "### 4.3. Modelo de Clustering 2: DBSCAN\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) es un algoritmo basado en densidad que agrupa puntos que están densamente conectados, marcando como ruido los puntos que se encuentran en regiones de baja densidad."
      ],
      "metadata": {
        "id": "aW4-P5oN_xSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TAREAS EN EL NOTEBOOK:\n",
        "1.  **Paso 1: Determinar `eps` y `min_samples` óptimos.**\n",
        "    * Establecer un `min_samples` inicial (ej., `2 * numero_de_features` o 5).\n",
        "    * Calcular las distancias al `min_samples`-ésimo vecino más cercano para cada punto.\n",
        "    * Graficar estas distancias ordenadas.\n",
        "    * Identificar el \"codo\" en el gráfico para estimar un `eps_elegido` y justificarlo en un comentario markdown."
      ],
      "metadata": {
        "id": "j-2lQ5oN_xSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9L-D5oN_xSs"
      },
      "outputs": [],
      "source": [
        "# Para min_samples, un valor común es 2 * número_de_dimensiones, o simplemente 5.\n",
        "# Para este dataset de vinos (11 dimensiones), usemos un min_samples inicial de 22 (2*11).\n",
        "min_samples_dbscan = 22 # Experimenta con otros valores, ej. 5\n",
        "\n",
        "# Encontrar las distancias al k-ésimo vecino más cercano\n",
        "neighbors = NearestNeighbors(n_neighbors=min_samples_dbscan)\n",
        "neighbors_fit = neighbors.fit(X_scaled)\n",
        "distances, indices = neighbors_fit.kneighbors(X_scaled)\n",
        "\n",
        "# Ordenar las distancias del k-ésimo vecino\n",
        "distances = np.sort(distances[:, min_samples_dbscan-1], axis=0) # Indexamos min_samples-1 porque es el k-ésimo vecino\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(distances)\n",
        "plt.title(f'Distancia al {min_samples_dbscan}-ésimo Vecino Más Cercano (para estimar eps)')\n",
        "plt.xlabel('Puntos ordenados por distancia')\n",
        "plt.ylabel(f'Distancia al {min_samples_dbscan}-ésimo Vecino')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# (A COMPLETAR) Justifica tu elección de eps aquí\n",
        "# Por ejemplo: \"Observando el gráfico de distancias, el 'codo' más pronunciado parece estar alrededor de eps = Y. Por lo tanto, elegimos Y.\"\n",
        "eps_elegido = None # Reemplaza None con el valor de eps que elegiste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Paso 2: Ejecutar DBSCAN.**\n",
        "    * Inicializar y entrenar `DBSCAN` con `eps=eps_elegido` y `min_samples=min_samples_dbscan`.\n",
        "    * Obtener las asignaciones de cluster usando `.fit_predict(X_scaled)`. Guardar en `clusters_dbscan`.\n",
        "    * Mostrar la cuenta de puntos por cluster, destacando el cluster `-1` (ruido)."
      ],
      "metadata": {
        "id": "mN0-D5oN_xSt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ1-D5oN_xSt"
      },
      "outputs": [],
      "source": [
        "if eps_elegido is not None:\n",
        "    dbscan_final = DBSCAN(eps=eps_elegido, min_samples=min_samples_dbscan)\n",
        "    clusters_dbscan = dbscan_final.fit_predict(X_scaled)\n",
        "\n",
        "    print(f\"Número de puntos por cluster (DBSCAN con eps={eps_elegido}, min_samples={min_samples_dbscan}):\")\n",
        "    print(pd.Series(clusters_dbscan).value_counts().sort_index())\n",
        "else:\n",
        "    print(\"Por favor, define 'eps_elegido' en la celda anterior.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Paso 3: Evaluación de DBSCAN con Silhouette Score (excluyendo ruido).**\n",
        "    * Calcular y mostrar el `silhouette_score` para DBSCAN, **excluyendo los puntos clasificados como ruido** (`clusters_dbscan != -1`).\n",
        "    * Opcional: Calcular Calinski-Harabasz Score y Davies-Bouldin Score (excluyendo ruido)."
      ],
      "metadata": {
        "id": "wX2-D5oN_xSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB6-D5oN_xSv"
      },
      "outputs": [],
      "source": [
        "if 'clusters_dbscan' in locals():\n",
        "    valid_indices = clusters_dbscan != -1\n",
        "    if np.unique(clusters_dbscan[valid_indices]).size > 1: # Asegurarse de que haya al menos 2 clusters válidos\n",
        "        silhouette_avg_dbscan = silhouette_score(X_scaled[valid_indices], clusters_dbscan[valid_indices])\n",
        "        print(f\"Silhouette Score para DBSCAN (excluyendo ruido): {silhouette_avg_dbscan:.3f}\")\n",
        "\n",
        "        calinski_dbscan = calinski_harabasz_score(X_scaled[valid_indices], clusters_dbscan[valid_indices])\n",
        "        davies_dbscan = davies_bouldin_score(X_scaled[valid_indices], clusters_dbscan[valid_indices])\n",
        "        print(f\"Calinski-Harabasz Score para DBSCAN: {calinski_dbscan:.3f}\")\n",
        "        print(f\"Davies-Bouldin Score para DBSCAN: {davies_dbscan:.3f}\")\n",
        "    else:\n",
        "        print(\"No hay suficientes clusters válidos (más de 1) en DBSCAN para calcular Silhouette Score.\")\n",
        "else:\n",
        "    print(\"Por favor, ejecuta las celdas anteriores para generar los clusters de DBSCAN.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"conclusion_clustering\"></a>\n",
        "### 4.4. (A COMPLETAR) Tareas Finales de Clustering y Conclusión\n",
        "No basta con aplicar los algoritmos; es crucial entender qué nos dicen los clusters y cuál enfoque es más adecuado para nuestro dataset de vinos."
      ],
      "metadata": {
        "id": "iN6-D5oN_xSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TAREAS EN EL NOTEBOOK:\n",
        "1.  **Métricas Clave:**\n",
        "    * Recopilen los `Silhouette Score` de KMeans y DBSCAN. ¿Cuál algoritmo obtuvo un mejor score y qué implica en términos de cohesión y separación de clusters?"
      ],
      "metadata": {
        "id": "qP9fD5oN_xSw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL0-D5oN_xSx"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Comparación de Métricas de Clustering ---\")\n",
        "if 'silhouette_avg_kmeans' in locals():\n",
        "    print(f\"KMeans (K={k_elegido}): Silhouette Score = {silhouette_avg_kmeans:.3f}\")\n",
        "if 'silhouette_avg_dbscan' in locals():\n",
        "    print(f\"DBSCAN (eps={eps_elegido}, min_samples={min_samples_dbscan}): Silhouette Score = {silhouette_avg_dbscan:.3f}\")\n",
        "\n",
        "# (A COMPLETAR) Compara y comenta los scores aquí:\n",
        "# \"Basado en el Silhouette Score, [KMeans/DBSCAN] parece generar clusters con mejor separación y cohesión interna debido a...\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Análisis de Clusters vs. Etiquetas Originales:**\n",
        "    * Para el clustering que consideren \"mejor\" o más interesante, analicen la distribución de las etiquetas `y_type` (tipo de vino: tinto/blanco) y `y_quality` (calidad del vino) dentro de cada cluster.\n",
        "    * Pueden usar `pd.crosstab()` o gráficos de barras/conteo para visualizar esto.\n",
        "    * ¿Hay algún cluster que sea predominantemente de un tipo de vino o de una calidad particular?"
      ],
      "metadata": {
        "id": "bT4-D5oN_xSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR8-D5oN_xS0"
      },
      "outputs": [],
      "source": [
        "# (A COMPLETAR) Elige el conjunto de clusters que consideres más interesante (ej. clusters_kmeans o clusters_dbscan)\n",
        "clusters_para_analisis = clusters_kmeans # O clusters_dbscan\n",
        "\n",
        "if 'clusters_para_analisis' in locals():\n",
        "    # Análisis de clusters vs. Tipo de Vino\n",
        "    print(\"\\n--- Análisis de Clusters vs. Tipo de Vino Original ---\")\n",
        "    crosstab_type = pd.crosstab(clusters_para_analisis, y_type)\n",
        "    display(crosstab_type)\n",
        "\n",
        "    # Análisis de clusters vs. Calidad del Vino\n",
        "    print(\"\\n--- Análisis de Clusters vs. Calidad del Vino Original ---\")\n",
        "    crosstab_quality = pd.crosstab(clusters_para_analisis, y_quality)\n",
        "    display(crosstab_quality)\n",
        "\n",
        "    # (A COMPLETAR) Comenta tus observaciones sobre estos cruces:\n",
        "    # \"Observamos que el cluster X tiene una alta proporción de vinos [tintos/blancos]...\"\n",
        "    # \"En cuanto a la calidad, el cluster Y parece agrupar vinos de [alta/baja/media] calidad...\"\n",
        "else:\n",
        "    print(\"Por favor, asegúrate de que 'clusters_kmeans' o 'clusters_dbscan' estén definidos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Completar la Tabla de Resultados de Clustering:**\n",
        "    * Llenen la siguiente tabla resumen con los resultados de ambos algoritmos."
      ],
      "metadata": {
        "id": "bY2-D5oN_xS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Algoritmo | Parámetros Clave (K / eps, min_samples) | Nº Clusters Encontrados | Nº Outliers (DBSCAN) | Silhouette Score |\n",
        "|-----------|-----------------------------------------|-------------------------|----------------------|------------------|\n",
        "| KMeans    | `K = [Tu K]`                            | `[Tu Nº Clusters]`      | N/A                  | `[Tu Score]`     |\n",
        "| DBSCAN    | `eps = [Tu eps], min_samples = [Tu min_samples]` | `[Tu Nº Clusters]`      | `[Tu Nº Outliers]`   | `[Tu Score]`     |"
      ],
      "metadata": {
        "id": "tD-2D5oN_xS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  **Justificar:**\n",
        "    * Escriban una conclusión clara: ¿Qué algoritmo de clustering (KMeans o DBSCAN) eligen como el más \"revelador\" o útil para este dataset y por qué?\n",
        "    * Consideren la calidad de los clusters, la interpretabilidad de los resultados, la capacidad de manejar formas no esféricas y su capacidad para encontrar patrones significativos."
      ],
      "metadata": {
        "id": "cP9fD5oN_xS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "(A COMPLETAR) Mi Conclusión sobre el Mejor Algoritmo de Clustering:\n",
        "\n",
        "Basado en [métricas de evaluación, análisis de clusters vs. etiquetas originales, y observaciones visuales], considero que el algoritmo [KMeans / DBSCAN] es el más adecuado para descubrir la estructura natural de este dataset de vinos porque...\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "rJ0-D5oN_xS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"reduccion_dim\"></a>\n",
        "# 5. Tarea 2: Reducción de Dimensionalidad y Visualización\n",
        "Dado que nuestros datos tienen 11 características, es difícil visualizarlos. Aplicaremos técnicas de reducción de dimensionalidad para proyectar los datos a 2 dimensiones, permitiéndonos ver la estructura de los clusters encontrados."
      ],
      "metadata": {
        "id": "eL0-D5oN_xS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"prep_reduccion\"></a>\n",
        "### 5.1. Preparación de Datos para Reducción de Dimensionalidad\n",
        "La entrada para las técnicas de reducción de dimensionalidad serán los datos escalados (`X_scaled`) que preparamos previamente."
      ],
      "metadata": {
        "id": "mP9fD5oN_xS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9L-D5oN_xS3"
      },
      "outputs": [],
      "source": [
        "print(f\"Los datos de entrada para la reducción de dimensionalidad son X_scaled con forma: {X_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"pca\"></a>\n",
        "### 5.2. Técnica de Reducción 1: PCA para Visualización\n",
        "PCA (Principal Component Analysis) es una técnica de reducción de dimensionalidad lineal que busca las direcciones (componentes principales) en los datos que maximizan la varianza."
      ],
      "metadata": {
        "id": "wX2-D5oN_xS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TAREAS EN EL NOTEBOOK:\n",
        "1.  **Paso 1: Aplicar PCA.**\n",
        "    * Inicializar `PCA(n_components=2, random_state=42)`.\n",
        "    * Entrenar y transformar `X_scaled` usando `.fit_transform()`. Guardar en `X_pca`."
      ],
      "metadata": {
        "id": "hB6-D5oN_xS3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8V0D5oN_xS4"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"Forma de los datos después de PCA: {X_pca.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Paso 2: Visualizar Clusters de KMeans en PCA.**\n",
        "    * Crear un `scatter plot` de `X_pca` coloreado por `clusters_kmeans`.\n",
        "    * Añadir título, etiquetas de ejes y una barra de color."
      ],
      "metadata": {
        "id": "bT4-D5oN_xS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR8-D5oN_xS5"
      },
      "outputs": [],
      "source": [
        "if 'clusters_kmeans' in locals():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter_kmeans_pca = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_kmeans, cmap='viridis', alpha=0.7)\n",
        "    plt.title(f'KMeans Clusters (K={k_elegido}) en Proyección PCA')\n",
        "    plt.xlabel('Componente Principal 1')\n",
        "    plt.ylabel('Componente Principal 2')\n",
        "    plt.colorbar(scatter_kmeans_pca, label='Cluster KMeans', ticks=range(k_elegido))\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Por favor, ejecuta la sección de KMeans para obtener 'clusters_kmeans'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Paso 3: Visualizar Clusters de DBSCAN en PCA.**\n",
        "    * Crear un `scatter plot` de `X_pca` coloreado por `clusters_dbscan`.\n",
        "    * Añadir título, etiquetas de ejes y una barra de color."
      ],
      "metadata": {
        "id": "bY2-D5oN_xS5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD-2D5oN_xS6"
      },
      "outputs": [],
      "source": [
        "if 'clusters_dbscan' in locals():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter_dbscan_pca = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_dbscan, cmap='viridis', alpha=0.7)\n",
        "    plt.title(f'DBSCAN Clusters (eps={eps_elegido}, min_samples={min_samples_dbscan}) en Proyección PCA')\n",
        "    plt.xlabel('Componente Principal 1')\n",
        "    plt.ylabel('Componente Principal 2')\n",
        "    plt.colorbar(scatter_dbscan_pca, label='Cluster DBSCAN')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Por favor, ejecuta la sección de DBSCAN para obtener 'clusters_dbscan'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  **Paso 4: Comparación con Tipo de Vino Original.**\n",
        "    * Crear un `scatter plot` de `X_pca` coloreado por `y_type` (la etiqueta original de tinto/blanco).\n",
        "    * Añadir título, etiquetas de ejes y una barra de color interpretativa.\n",
        "    * Comentar las observaciones sobre la separación."
      ],
      "metadata": {
        "id": "cP9fD5oN_xS6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ0-D5oN_xS7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "scatter_original_pca = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_type, cmap='coolwarm', alpha=0.7)\n",
        "plt.title('Tipo de Vino Original en Proyección PCA')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.colorbar(scatter_original_pca, ticks=[0, 1], format=plt.FuncFormatter(lambda x, p: 'Tinto' if x==0 else 'Blanco'), label='Tipo de Vino')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# (A COMPLETAR) Comenta aquí tus observaciones sobre la separación con PCA\n",
        "# \"PCA logra [una buena/mala] separación visual de los vinos por tipo, lo que indica...\"\n",
        "# \"Los clusters encontrados por KMeans/DBSCAN se [alinean/no alinean] bien con la separación de PCA...\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"tsne\"></a>\n",
        "### 5.3. Técnica de Reducción 2: t-SNE para Visualización\n",
        "t-SNE (t-Distributed Stochastic Neighbor Embedding) es una técnica no lineal que se enfoca en preservar las relaciones de proximidad local, lo que la hace excelente para visualizar agrupamientos (clusters)."
      ],
      "metadata": {
        "id": "eL0-D5oN_xS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TAREAS EN EL NOTEBOOK:\n",
        "1.  **Paso 1: Aplicar t-SNE.**\n",
        "    * Inicializar `TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)`.\n",
        "    * Entrenar y transformar `X_scaled` usando `.fit_transform()`. Guardar en `X_tsne`. (¡Este paso puede tardar varios segundos/minutos!)."
      ],
      "metadata": {
        "id": "mP9fD5oN_xS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9L-D5oN_xS8"
      },
      "outputs": [],
      "source": [
        "print(\"Ejecutando t-SNE... (esto puede tomar un tiempo considerable)\")\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "X_tsne = tsne.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"Forma de los datos después de t-SNE: {X_tsne.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Paso 2: Visualizar Clusters de KMeans en t-SNE.**\n",
        "    * Crear un `scatter plot` de `X_tsne` coloreado por `clusters_kmeans`.\n",
        "    * Añadir título, etiquetas de ejes y una barra de color."
      ],
      "metadata": {
        "id": "wX2-D5oN_xS9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB6-D5oN_xS9"
      },
      "outputs": [],
      "source": [
        "if 'clusters_kmeans' in locals():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter_kmeans_tsne = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=clusters_kmeans, cmap='viridis', alpha=0.7)\n",
        "    plt.title(f'KMeans Clusters (K={k_elegido}) en Proyección t-SNE')\n",
        "    plt.xlabel('t-SNE Componente 1')\n",
        "    plt.ylabel('t-SNE C omponente 2')\n",
        "    plt.colorbar(scatter_kmeans_tsne, label='Cluster KMeans', ticks=range(k_elegido))\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Por favor, ejecuta la sección de KMeans para obtener 'clusters_kmeans'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Paso 3: Visualizar Clusters de DBSCAN en t-SNE.**\n",
        "    * Crear un `scatter plot` de `X_tsne` coloreado por `clusters_dbscan`.\n",
        "    * Añadir título, etiquetas de ejes y una barra de color."
      ],
      "metadata": {
        "id": "s8V0D5oN_xSa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT4-D5oN_xSa"
      },
      "outputs": [],
      "source": [
        "if 'clusters_dbscan' in locals():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter_dbscan_tsne = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=clusters_dbscan, cmap='viridis', alpha=0.7)\n",
        "    plt.title(f'DBSCAN Clusters (eps={eps_elegido}, min_samples={min_samples_dbscan}) en Proyección t-SNE')\n",
        "    plt.xlabel('t-SNE Componente 1')\n",
        "    plt.ylabel('t-SNE Componente 2')\n",
        "    plt.colorbar(scatter_dbscan_tsne, label='Cluster DBSCAN')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Por favor, ejecuta la sección de DBSCAN para obtener 'clusters_dbscan'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  **Paso 4: Comparación con Tipo de Vino Original.**\n",
        "    * Crear un `scatter plot` de `X_tsne` coloreado por `y_type`.\n",
        "    * Añadir título, etiquetas de ejes y una barra de color interpretativa.\n",
        "    * Comentar las observaciones sobre la separación y la preservación local."
      ],
      "metadata": {
        "id": "bY2-D5oN_xSb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD-2D5oN_xSc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "scatter_original_tsne = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_type, cmap='coolwarm', alpha=0.7)\n",
        "plt.title('Tipo de Vino Original en Proyección t-SNE')\n",
        "plt.xlabel('t-SNE Componente 1')\n",
        "plt.ylabel('t-SNE Componente 2')\n",
        "plt.colorbar(scatter_original_tsne, ticks=[0, 1], format=plt.FuncFormatter(lambda x, p: 'Tinto' if x==0 else 'Blanco'), label='Tipo de Vino')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# (A COMPLETAR) Comenta aquí tus observaciones sobre la separación con t-SNE\n",
        "# \"t-SNE logra [una mejor/peor] separación visual de los clusters/tipos de vino en comparación con PCA, lo que sugiere...\"\n",
        "# \"Observamos que t-SNE tiende a formar agrupaciones más densas para los clusters...\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"umap\"></a>\n",
        "### 5.4. Técnica de Reducción 3: UMAP para Visualización\n",
        "UMAP (Uniform Manifold Approximation and Projection) es una técnica de reducción de dimensionalidad no lineal más reciente y a menudo más rápida que t-SNE, que busca un balance entre la preservación de la estructura local y global."
      ],
      "metadata": {
        "id": "cP9fD5oN_xSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TAREAS EN EL NOTEBOOK:\n",
        "1.  **Paso 1: Aplicar UMAP.**\n",
        "    * Inicializar `umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)` (puedes ajustar `n_neighbors` y `min_dist`).\n",
        "    * Entrenar y transformar `X_scaled` usando `.fit_transform()`. Guardar en `X_umap`."
      ],
      "metadata": {
        "id": "rJ0-D5oN_xSd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL0-D5oN_xSe"
      },
      "outputs": [],
      "source": [
        "print(\"Ejecutando UMAP... (generalmente más rápido que t-SNE)\")\n",
        "reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1) # Ajusta parámetros si es necesario\n",
        "X_umap = reducer.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"Forma de los datos después de UMAP: {X_umap.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Paso 2: Visualizar Clusters de KMeans en UMAP.**\n",
        "    * Crear un `scatter plot` de `X_umap` coloreado por `clusters_kmeans`.\n",
        "    * Añadir título, etiquetas de ejes y una barra de color."
      ],
      "metadata": {
        "id": "mP9fD5oN_xSe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9L-D5oN_xSf"
      },
      "outputs": [],
      "source": [
        "if 'clusters_kmeans' in locals():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter_kmeans_umap = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=clusters_kmeans, cmap='viridis', alpha=0.7)\n",
        "    plt.title(f'KMeans Clusters (K={k_elegido}) en Proyección UMAP')\n",
        "    plt.xlabel('UMAP Componente 1')\n",
        "    plt.ylabel('UMAP Componente 2')\n",
        "    plt.colorbar(scatter_kmeans_umap, label='Cluster KMeans', ticks=range(k_elegido))\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Por favor, ejecuta la sección de KMeans para obtener 'clusters_kmeans'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Paso 3: Visualizar Clusters de DBSCAN en UMAP.**\n",
        "    * Crear un `scatter plot` de `X_umap` coloreado por `clusters_dbscan`.\n",
        "    * Añadir título, etiquetas de ejes y una barra de color."
      ],
      "metadata": {
        "id": "wX2-D5oN_xSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB6-D5oN_xSg"
      },
      "outputs": [],
      "source": [
        "if 'clusters_dbscan' in locals():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter_dbscan_umap = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=clusters_dbscan, cmap='viridis', alpha=0.7)\n",
        "    plt.title(f'DBSCAN Clusters (eps={eps_elegido}, min_samples={min_samples_dbscan}) en Proyección UMAP')\n",
        "    plt.xlabel('UMAP Componente 1')\n",
        "    plt.ylabel('UMAP Componente 2')\n",
        "    plt.colorbar(scatter_dbscan_umap, label='Cluster DBSCAN')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Por favor, ejecuta la sección de DBSCAN para obtener 'clusters_dbscan'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  **Paso 4: Comparación con Tipo de Vino Original.**\n",
        "    * Crear un `scatter plot` de `X_umap` coloreado por `y_type`.\n",
        "    * Añadir título, etiquetas de ejes y una barra de color interpretativa.\n",
        "    * Comentar las observaciones sobre la separación, velocidad y preservación global/local."
      ],
      "metadata": {
        "id": "s8V0D5oN_xSh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT4-D5oN_xSh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "scatter_original_umap = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y_type, cmap='coolwarm', alpha=0.7)\n",
        "plt.title('Tipo de Vino Original en Proyección UMAP')\n",
        "plt.xlabel('UMAP Componente 1')\n",
        "plt.ylabel('UMAP Componente 2')\n",
        "plt.colorbar(scatter_original_umap, ticks=[0, 1], format=plt.FuncFormatter(lambda x, p: 'Tinto' if x==0 else 'Blanco'), label='Tipo de Vino')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# (A COMPLETAR) Comenta aquí tus observaciones sobre la separación con UMAP\n",
        "# \"UMAP parece ofrecer [una excelente/buena/regular] visualización, con clusters [más compactos/más dispersos] y [mejor/peor] preservación de la estructura global...\"\n",
        "# \"La separación de los tipos de vino original con UMAP es...\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"conclusion_reduccion\"></a>\n",
        "### 5.5. (A COMPLETAR) Tareas Finales de Reducción y Conclusión\n",
        "Una vez generadas todas las proyecciones visuales, es momento de analizar cuál método nos ofrece la visión más clara, perspicaz y útil de la estructura de nuestros datos y de los clusters encontrados."
      ],
      "metadata": {
        "id": "bY2-D5oN_xSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TAREAS EN EL NOTEBOOK:\n",
        "1.  **Comparación Visual Exhaustiva:**\n",
        "    * Vuelvan a revisar todos los gráficos de PCA, t-SNE y UMAP (con clusters de KMeans, DBSCAN y el tipo de vino original).\n",
        "    * ¿Cuál proyección muestra la mejor separación entre los clusters encontrados por KMeans y DBSCAN?\n",
        "    * ¿Cuál preserva mejor la separación natural entre vinos tintos y blancos?\n",
        "    * ¿Observan alguna estructura interesante (sub-grupos, outliers, continuidad) en alguna de las visualizaciones que no era evidente antes?"
      ],
      "metadata": {
        "id": "tD-2D5oN_xSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "(A COMPLETAR) Compara aquí las visualizaciones y la separación de clusters/tipos de vino:\n",
        "\n",
        "\"Al comparar las proyecciones de PCA, t-SNE y UMAP, se observa que [t-SNE/UMAP/PCA] es el que mejor logra visualizar la separación de los clusters de [KMeans/DBSCAN], mientras que [otro método] es mejor para el tipo de vino original porque...\"\n",
        "\n",
        "\"Algunas estructuras interesantes observadas son...\"\n",
        "```"
      ],
      "metadata": {
        "id": "cP9fD5oN_xSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Consideraciones de Rendimiento:**\n",
        "    * Comenten brevemente sobre el tiempo de ejecución aproximado de cada método de reducción de dimensionalidad (PCA es rápido, t-SNE es lento, UMAP intermedio)."
      ],
      "metadata": {
        "id": "rJ0-D5oN_xSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "(A COMPLETAR) Comentarios sobre el rendimiento:\n",
        "\n",
        "\"En términos de velocidad, PCA fue el más rápido, seguido por UMAP. t-SNE fue el más lento, lo cual es de esperar para datasets de este tamaño.\"\n",
        "```"
      ],
      "metadata": {
        "id": "eL0-D5oN_xSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Justificar:**\n",
        "    * Escriban una conclusión clara: ¿Qué técnica de reducción de dimensionalidad (PCA, t-SNE o UMAP) consideran más efectiva para **visualizar** la estructura de este dataset de vinos en particular, y por qué?\n",
        "    * Argumenten su elección basándose en la claridad de los clusters, la preservación de la estructura original y la eficiencia computacional."
      ],
      "metadata": {
        "id": "mP9fD5oN_xSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "(A COMPLETAR) Mi Conclusión sobre la Mejor Técnica de Reducción de Dimensionalidad para Visualización:\n",
        "\n",
        "Basado en [la claridad visual, la preservación de estructuras y el rendimiento], considero que [PCA / t-SNE / UMAP] es la técnica más efectiva para visualizar este dataset porque...\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "z9L-D5oN_xSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"final\"></a>\n",
        "# 6. Conclusiones: A COMPLETAR Conclusiones Finales del Proyecto\n",
        "En esta sección final, resume tus hallazgos clave de todo el proyecto integrador del Módulo 3. ¡Es tu oportunidad para mostrar todo lo que aprendiste!"
      ],
      "metadata": {
        "id": "wX2-D5oN_xSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TAREAS EN EL NOTEBOOK:\n",
        "\n",
        "1.  **Resumen de Hallazgos Clave:**\n",
        "    * ¿Qué descubriste sobre la estructura intrínseca de los datos de vino a través del clustering?\n",
        "    * ¿Cómo te ayudaron las técnicas de reducción de dimensionalidad a entender mejor estas estructuras? ¿Hubo alguna visualización que te sorprendiera o te diera una nueva perspectiva?\n",
        "    * ¿Consideras que los clusters encontrados se correlacionan con características significativas del vino (ej. tipo, calidad, otros perfiles no obvios)?\n",
        "\n",
        "2.  **Desafíos y Aprendizajes:**\n",
        "    * ¿Cuáles fueron los principales desafíos al trabajar con modelos no supervisados y reducción de dimensionalidad en este dataset?\n",
        "    * ¿Qué nuevos aprendizajes clave te llevas de este módulo y este proyecto?\n",
        "\n",
        "3.  **Aplicaciones Futuras:**\n",
        "    * ¿Cómo crees que estas técnicas no supervisadas podrían aplicarse en escenarios reales de la industria del vino o en otros dominios? (ej. segmentación de clientes, detección de anomalías, descubrimiento de nuevas categorías de productos).\n"
      ],
      "metadata": {
        "id": "hB6-D5oN_xSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "(A COMPLETAR) Tus Conclusiones Finales Aquí:\n",
        "\n",
        "\"Este proyecto integrador nos permitió adentrarnos en el mundo del aprendizaje no supervisado, revelando patrones y estructuras ocultas en el dataset de vinos que no serían evidentes con un análisis supervisado tradicional...\"\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "s8V0D5oN_xSn"
      }
    }
  ]
}